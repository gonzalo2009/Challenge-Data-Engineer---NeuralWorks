{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from datetime import datetime, time, timedelta\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conexiones a la base de datos\n",
    "conn = psycopg2.connect(\n",
    "    host='localhost',\n",
    "    database='data_engineer',\n",
    "    user='postgres',\n",
    "    port='5434',\n",
    "    password='Pomelo5075.'\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "conn_string = 'postgresql+psycopg2://postgres:Pomelo5075.@localhost:5434/data_engineer'\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn_db = db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea en la base de datos el esquema la tabla de viajes y e inserta las viajes del archivo .csv\n",
    "cur.execute(f'''create schema data_engineer''')\n",
    "\n",
    "cur.execute(f'''\n",
    "create table  data_engineer.trips (\n",
    "    region varchar(50),\n",
    "    origin_coord point, \n",
    "    destination_coord point,\n",
    "    datetime timestamp,\n",
    "    datasource varchar(50)\n",
    ");\n",
    "''')\n",
    "\n",
    "\n",
    "df = pd.read_csv('trips.csv')\n",
    "df['origin_coord'] = df['origin_coord'].apply(\n",
    "    lambda x: ', '.join(x.split()[1:]))\n",
    "df['destination_coord'] = df['destination_coord'].apply(\n",
    "    lambda x: ', '.join(x.split()[1:]))\n",
    "\n",
    "rows = ', '.join(list(df.apply(\n",
    "    lambda x: f\"('{x[0]}', '{x[1]}', '{x[2]}', '{x[3]}', '{x[4]}')\", axis=1)))\n",
    "\n",
    "cur.execute(f'''INSERT into data_engineer.trips values {rows}''')\n",
    "\n",
    "\n",
    "# Crea una segunda tabla de \"intervalos\" que se usara para determinar que viajes son similares\n",
    "cur.execute(f'''\n",
    "    create table data_engineer.similar_trips ( \n",
    "        id  SERIAL primary key,\n",
    "        region varchar(50),\n",
    "        square box,\n",
    "        time_start time,\n",
    "        time_end time\n",
    "    )\n",
    "''')\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pregunta 1\n",
    "#a. Para determinar si los viaje son similares se dividio cada region en rectangulos de un 1° de latitud y longitud y el tiempo \n",
    "# del día en intervalos de una hora. Entonces dos viajes que tienen el origen en el mismo rectangulo, el destino en el mismo rectangulo y \n",
    "# están dentro del mismo intervalo de tiempo en el día se consideran similares. Para agrupar los viajes similares se contruye la \n",
    "# tabla de intervalos en que cada registro corresponde a un rectangulo de una región, a un intervalo del día acompañado de un id \n",
    "# del registro. Esta tabla se cruza con la tabla original de viajes dos veces. Pimero se cruza con la condición de que el \n",
    "# origen este dentro del rectangulo y el tiempo este dentro del intervalo y después con la condición de que el destino este \n",
    "# dentro del rectangulo y el tiempo este dentro del intervalo. Cruzando las tablas se puede determinar que viajes tuvieron \n",
    "# origenes, destinos y tiempos similares.\n",
    "\n",
    "def get_similar_trips():\n",
    "    #Se crea una lista con los intervalos de tiempo  \n",
    "    time_range_list = []\n",
    "    time_start = datetime(2022, 1, 1)\n",
    "    while True:\n",
    "        if time_start.time() < datetime(2022, 1, 1, 23).time():\n",
    "            time_end = time_start + timedelta(minutes=60)\n",
    "            time_range_list.append((time_start.time().strftime(\n",
    "                \"%H:%M:%S\"), time_end.time().strftime(\"%H:%M:%S\")))\n",
    "        else:\n",
    "            time_end = datetime(2022, 1, 1, 23, 59, 59)\n",
    "            time_range_list.append((time_start.time().strftime(\n",
    "                \"%H:%M:%S\"), time_end.time().strftime(\"%H:%M:%S\")))\n",
    "            break\n",
    "        time_start = time_end\n",
    "\n",
    "    #Se crea un dataframe con las latitudes maximas y minimas y las longitudes  maximas y minimas por region con el objetivo de \n",
    "    #dividir las coodenadas en segmentos y lograr construir un 'cuadriculado' en cada región\n",
    "    df_regions = pd.read_sql(\n",
    "        ''' \n",
    "        SELECT \n",
    "            region,\n",
    "            max(origin_coord[0]) max_x, \n",
    "            max(origin_coord[1]) max_y , \n",
    "            min(origin_coord[0]) min_x, \n",
    "            min(origin_coord[1]) min_y \n",
    "        from \n",
    "            data_engineer.trips \n",
    "        group by\n",
    "            region\n",
    "        ''',\n",
    "        con=conn_db\n",
    "    )\n",
    "\n",
    "    edge_len = 1\n",
    "\n",
    "\n",
    "    #Se crea un dataframe con la combinatoria de todos los rectangulos e intervalos de tiempo por región.\n",
    "    df = pd.DataFrame()\n",
    "    for i in df_regions.iterrows():\n",
    "        min_x = i[1]['min_x']\n",
    "        max_x = i[1]['max_x']\n",
    "        vertices_x_list = []\n",
    "\n",
    "        min_x_vertice = min_x\n",
    "        max_x_vertice = min_x + edge_len\n",
    "\n",
    "        while True:\n",
    "            vertices_x_list.append((min_x_vertice, max_x_vertice))\n",
    "            if max_x_vertice >= max_x:\n",
    "                break\n",
    "            min_x_vertice = max_x_vertice\n",
    "            max_x_vertice += edge_len\n",
    "\n",
    "        min_y = i[1]['min_y']\n",
    "        max_y = i[1]['max_y']\n",
    "        vertices_y_list = []\n",
    "\n",
    "        min_y_vertice = min_y\n",
    "        max_y_vertice = min_y + edge_len\n",
    "\n",
    "        while True:\n",
    "            vertices_y_list.append((min_y_vertice, max_y_vertice))\n",
    "            if max_y_vertice >= max_y:\n",
    "                break\n",
    "            min_y_vertice = max_y_vertice\n",
    "            max_y_vertice += edge_len\n",
    "            \n",
    "        squares_list = [((i[0], j[0]), (i[1], j[1])) for i in vertices_x_list for j in vertices_y_list]\n",
    "        data = [[i, j] for i in squares_list for j in time_range_list]\n",
    "\n",
    "        squares_list = [i[0] for i in data]\n",
    "        time_start_list = [i[1][0] for i in data]\n",
    "        time_end_list = [i[1][1] for i in data]\n",
    "        df_current = pd.DataFrame({'square': squares_list,\n",
    "                        'time_start': time_start_list, 'time_end': time_end_list})\n",
    "        df_current['square'] = df_current['square'].astype(str)\n",
    "\n",
    "        df_current.insert(0, 'region', i[1]['region'])\n",
    "        df = pd.concat([df, df_current])\n",
    "\n",
    "\n",
    "    rows = ', '.join(list(df.apply(\n",
    "        lambda x: f\"('{x[0]}', '{x[1]}', '{x[2]}', '{x[3]}')\", axis=1)))\n",
    "\n",
    "    cur.execute(\n",
    "        f'''insert into data_engineer.similar_trips(region, square, time_start, time_end) values {rows}''')  \n",
    "    conn.commit()\n",
    "\n",
    "    #Se cruzan las tablas para encontrar los viajes similares\n",
    "    df_trips_groups = pd.read_sql(\n",
    "        '''\n",
    "        select\n",
    "            concat( '(', t2.id, ',' ,t3.id,')')  trip_id,\n",
    "            t1.*\n",
    "        from \n",
    "            data_engineer.trips t1\n",
    "        left join  data_engineer.similar_trips t2 \n",
    "            on \tt1.region = t2.region\n",
    "            and t2.square @> t1.origin_coord\n",
    "            and cast(t1.datetime as time) > t2.time_start  \n",
    "            and cast(t1.datetime as time) < t2.time_end  \n",
    "        left join  data_engineer.similar_trips t3 \n",
    "            on \tt1.region = t3.region\n",
    "            and t3.square @> t1.destination_coord\n",
    "            and cast(t1.datetime as time) > t3.time_start  \n",
    "            and cast(t1.datetime as time) < t3.time_end \t\n",
    "        order by \n",
    "            t2.id,\n",
    "            t3.id \n",
    "        ''',\n",
    "        con=conn_db)\n",
    "\n",
    "    return df_trips_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>region</th>\n",
       "      <th>origin_coord</th>\n",
       "      <th>destination_coord</th>\n",
       "      <th>datetime</th>\n",
       "      <th>datasource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1,1)</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>(10.05260098579818,53.53497739746809)</td>\n",
       "      <td>(10.05889649564977,53.49486429314853)</td>\n",
       "      <td>2018-05-04 00:46:12</td>\n",
       "      <td>cheap_mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2,2)</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>(10.02610136178745,53.50122432388112)</td>\n",
       "      <td>(9.83414766930147,53.6513082275632)</td>\n",
       "      <td>2018-05-14 01:47:52</td>\n",
       "      <td>baba_car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(4,4)</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>(10.1457401708168,53.43686908113324)</td>\n",
       "      <td>(10.19421502623748,53.49444402955017)</td>\n",
       "      <td>2018-05-10 03:37:56</td>\n",
       "      <td>bad_diesel_vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(5,5)</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>(10.17378993097742,53.5467336774148)</td>\n",
       "      <td>(10.21529787231755,53.50485266884467)</td>\n",
       "      <td>2018-05-21 04:06:11</td>\n",
       "      <td>pt_search_app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(5,5)</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>(10.06118280297654,53.46738240063593)</td>\n",
       "      <td>(10.20354128171305,53.51109692120344)</td>\n",
       "      <td>2018-05-17 04:27:09</td>\n",
       "      <td>baba_car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(67,67)</td>\n",
       "      <td>Turin</td>\n",
       "      <td>(7.723807753167536,45.02971128289503)</td>\n",
       "      <td>(7.592874526101529,45.0395824302331)</td>\n",
       "      <td>2018-05-24 18:32:22</td>\n",
       "      <td>pt_search_app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>(68,68)</td>\n",
       "      <td>Turin</td>\n",
       "      <td>(7.592730702551875,45.10999018294942)</td>\n",
       "      <td>(7.714926530712359,45.0772550203861)</td>\n",
       "      <td>2018-05-18 19:29:56</td>\n",
       "      <td>bad_diesel_vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(69,69)</td>\n",
       "      <td>Turin</td>\n",
       "      <td>(7.671077441892763,45.00676340143624)</td>\n",
       "      <td>(7.7199332961156,44.98171705467543)</td>\n",
       "      <td>2018-05-15 20:30:12</td>\n",
       "      <td>pt_search_app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(70,70)</td>\n",
       "      <td>Turin</td>\n",
       "      <td>(7.676692231736426,45.06249909939103)</td>\n",
       "      <td>(7.686960868773017,45.09709631077637)</td>\n",
       "      <td>2018-05-21 21:32:17</td>\n",
       "      <td>baba_car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>(71,71)</td>\n",
       "      <td>Turin</td>\n",
       "      <td>(7.563475091132667,44.97997955620617)</td>\n",
       "      <td>(7.517129937471816,45.06482486034779)</td>\n",
       "      <td>2018-05-13 22:16:27</td>\n",
       "      <td>pt_search_app</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    trip_id   region                           origin_coord  \\\n",
       "0     (1,1)  Hamburg  (10.05260098579818,53.53497739746809)   \n",
       "1     (2,2)  Hamburg  (10.02610136178745,53.50122432388112)   \n",
       "2     (4,4)  Hamburg   (10.1457401708168,53.43686908113324)   \n",
       "3     (5,5)  Hamburg   (10.17378993097742,53.5467336774148)   \n",
       "4     (5,5)  Hamburg  (10.06118280297654,53.46738240063593)   \n",
       "..      ...      ...                                    ...   \n",
       "95  (67,67)    Turin  (7.723807753167536,45.02971128289503)   \n",
       "96  (68,68)    Turin  (7.592730702551875,45.10999018294942)   \n",
       "97  (69,69)    Turin  (7.671077441892763,45.00676340143624)   \n",
       "98  (70,70)    Turin  (7.676692231736426,45.06249909939103)   \n",
       "99  (71,71)    Turin  (7.563475091132667,44.97997955620617)   \n",
       "\n",
       "                        destination_coord            datetime  \\\n",
       "0   (10.05889649564977,53.49486429314853) 2018-05-04 00:46:12   \n",
       "1     (9.83414766930147,53.6513082275632) 2018-05-14 01:47:52   \n",
       "2   (10.19421502623748,53.49444402955017) 2018-05-10 03:37:56   \n",
       "3   (10.21529787231755,53.50485266884467) 2018-05-21 04:06:11   \n",
       "4   (10.20354128171305,53.51109692120344) 2018-05-17 04:27:09   \n",
       "..                                    ...                 ...   \n",
       "95   (7.592874526101529,45.0395824302331) 2018-05-24 18:32:22   \n",
       "96   (7.714926530712359,45.0772550203861) 2018-05-18 19:29:56   \n",
       "97    (7.7199332961156,44.98171705467543) 2018-05-15 20:30:12   \n",
       "98  (7.686960868773017,45.09709631077637) 2018-05-21 21:32:17   \n",
       "99  (7.517129937471816,45.06482486034779) 2018-05-13 22:16:27   \n",
       "\n",
       "             datasource  \n",
       "0          cheap_mobile  \n",
       "1              baba_car  \n",
       "2   bad_diesel_vehicles  \n",
       "3         pt_search_app  \n",
       "4              baba_car  \n",
       "..                  ...  \n",
       "95        pt_search_app  \n",
       "96  bad_diesel_vehicles  \n",
       "97        pt_search_app  \n",
       "98             baba_car  \n",
       "99        pt_search_app  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pregunta 1\n",
    "#Cuando dos viajes tiene el mismo valor en la columna trip_id significa que son similares\n",
    "get_similar_trips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pregunta 2\n",
    "#La siguiente función tiene como parámetros la latitud y longitud minima y la latitud y longitud maxima y la región. Con esto\n",
    "#se hace un llamado a la base de datos para obtener el promedio semanal. retorna un objeto con \n",
    "# el promedio y el estado final de la base de datos. \n",
    "def get_weekly_average(x1,y1,x2,y2, region):\n",
    "    df = pd.read_sql(\n",
    "        f'''\n",
    "        select\n",
    "            (select \n",
    "                count(origin_coord) \n",
    "            from \n",
    "                data_engineer.trips \n",
    "            where\n",
    "                cast('({x1},{y1}),({x2},{y2})' as box) @> origin_coord\n",
    "                and cast('({x1},{y1}),({x2},{y2})' as box) @> destination_coord\n",
    "                and region='{region}')/\n",
    "            (select extract(epoch from (select max(datetime) - min(datetime) from data_engineer.trips))/(60 * 60 * 24 * 7))\n",
    "        ''',\n",
    "        con=conn_db)\n",
    "\n",
    "    return {'average': df.iloc[0,0], 'status': conn.poll()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average': 5.318049192260874, 'status': 0}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pregunta 2\n",
    "get_weekly_average(10.80304883152659,54.42865933587807, 9.80304883152659,53.42865933587807, 'Hamburg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()\n",
    "conn_db.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
